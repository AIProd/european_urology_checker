import operator
import os
from dotenv import load_dotenv
from typing import Annotated, List, TypedDict

from langchain_core.prompts import ChatPromptTemplate
from langchain_community.vectorstores import Chroma
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langgraph.graph import StateGraph, END

load_dotenv()

DB_DIR = "./chroma_db"

# --- 1. STATE DEFINITION ---
class AgentState(TypedDict):
    paper_content: str
    paper_type: str 
    audit_logs: Annotated[List[str], operator.add]
    final_report: str

# --- 2. SETUP MODELS & DB ---
def get_azure_resources():
    if not os.getenv("AZURE_OPENAI_API_KEY"):
        raise ValueError("Azure keys missing from .env")

    llm = AzureChatOpenAI(
        azure_deployment=os.getenv("AZURE_DEPLOYMENT_NAME"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        temperature=0
    )

    embedding_function = AzureOpenAIEmbeddings(
        model=os.getenv("AZURE_EMBEDDING_DEPLOYMENT"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
    )
    
    return llm, embedding_function

# Initialize strictly for graph building
try:
    llm, embedding_function = get_azure_resources()
    if os.path.exists(DB_DIR):
        vectorstore = Chroma(persist_directory=DB_DIR, embedding_function=embedding_function)
        retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
    else:
        retriever = None
except Exception as e:
    print(f"Initialization Warning: {e}")
    llm = None
    retriever = None


# --- 3. NODES ---

def classifier_node(state: AgentState):
    content_snippet = state["paper_content"][:3000]
    prompt = ChatPromptTemplate.from_template(
        "Analyze the following introduction/abstract. "
        "Classify strictly as one of: 'Systematic Review', 'Meta-analysis', "
        "'Randomized Clinical Trial', or 'Observational Study'. "
        "Return ONLY the category name.\n\nText: {text}"
    )
    chain = prompt | llm
    category = chain.invoke({"text": content_snippet}).content
    return {"paper_type": category, "audit_logs": [f"**Paper classified as:** {category}"]}

def general_auditor_node(state: AgentState):
    if not retriever:
        return {"audit_logs": ["*Error: DB not found. Run indexer.py*"]}

    general_rules = retriever.get_relevant_documents("p-values confidence intervals significant figures exact p-values")
    rule_text = "\n".join([doc.page_content for doc in general_rules])
    
    prompt = ChatPromptTemplate.from_template(
        "You are a Statistical Editor for European Urology. "
        "Check snippet against GUIDELINES:\n{rules}\n\n"
        "PAPER SNIPPET:\n{paper}\n\n"
        "Identify 3-5 critical statistical reporting errors. If none, say 'General Stats: Pass'."
    )
    
    mid_point = len(state["paper_content"]) // 2
    paper_snippet = state["paper_content"][max(0, mid_point-2000) : min(len(state["paper_content"]), mid_point+2000)]
    
    response = (prompt | llm).invoke({"rules": rule_text, "paper": paper_snippet})
    return {"audit_logs": [f"### General Stats Check\n{response.content}"]}

def specific_auditor_node(state: AgentState):
    if not retriever:
        return {}

    paper_type = state["paper_type"]
    query = ""
    if "Systematic" in paper_type or "Meta" in paper_type:
        query = "PRISMA guidelines systematic review meta-analysis checklist"
    elif "Observational" in paper_type:
        query = "causality causal language observational study confounding"
    else:
        query = "randomized clinical trial CONSORT"
        
    specific_rules = retriever.get_relevant_documents(query)
    rule_text = "\n".join([doc.page_content for doc in specific_rules])
    
    prompt = ChatPromptTemplate.from_template(
        "Check compliance for '{ptype}'. "
        "Guidelines:\n{rules}\n\n"
        "Check Discussion/Conclusion for violations.\n"
        "PAPER TEXT:\n{paper}\n\n"
        "Report violations briefly."
    )
    
    end_text = state["paper_content"][-3000:]
    response = (prompt | llm).invoke({"ptype": paper_type, "rules": rule_text, "paper": end_text})
    
    return {"audit_logs": [f"### Specific Guideline Check ({paper_type})\n{response.content}"]}

def reporter_node(state: AgentState):
    logs = "\n\n".join(state["audit_logs"])
    report = f"# ðŸ‡ªðŸ‡º European Urology Statistical Report\n**Detected Type:** {state['paper_type']}\n\n---\n{logs}\n\n---\n*Generated by AI Agent*"
    return {"final_report": report}

# --- 4. GRAPH BUILD ---
workflow = StateGraph(AgentState)
workflow.add_node("classify", classifier_node)
workflow.add_node("check_general", general_auditor_node)
workflow.add_node("check_specific", specific_auditor_node)
workflow.add_node("report", reporter_node)

workflow.set_entry_point("classify")
workflow.add_edge("classify", "check_general")
workflow.add_edge("check_general", "check_specific")
workflow.add_edge("check_specific", "report")
workflow.add_edge("report", END)

app_graph = workflow.compile()
